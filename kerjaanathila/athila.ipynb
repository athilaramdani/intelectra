{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96f55ed",
   "metadata": {},
   "source": [
    "# Intellectra 2025 â€“ Next-Buy Prediction\n",
    "\n",
    "End-to-end workflow to maximise **Balanced Accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79b7974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Cell 0 â€“ Install (run once, skip if libs already installed)\n",
    "!pip install -q lightgbm optuna pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72ac0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED SOLUTION FOR BETTER SCORE\n",
    "# ===========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from datetime import datetime, timedelta\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA_DIR = Path(r\"F:/lomba/intelectra/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6be5c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading and preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 1. ENHANCED DATA LOADING\n",
    "# ================================\n",
    "print(\"ðŸ”„ Loading and preprocessing data...\")\n",
    "\n",
    "# Load data with proper parsing\n",
    "member = pd.read_csv(DATA_DIR/'member_data.csv', \n",
    "                    parse_dates=['JoinDate', 'DateOfBirth', 'EldestKidDOB', 'YoungestKidDOB'])\n",
    "product = pd.read_csv(DATA_DIR/'product_data.csv', \n",
    "                     names=['productID', 'ProductName', 'ProductCategory', 'ProductLevel'])\n",
    "program = pd.read_csv(DATA_DIR/'program_data.csv')\n",
    "train_trx = pd.read_csv(DATA_DIR/'train_transaction_data.csv', \n",
    "                       parse_dates=['TransactionDatetime'])\n",
    "test_trx = pd.read_csv(DATA_DIR/'test_transaction_data.csv', \n",
    "                      parse_dates=['TransactionDatetime'])\n",
    "train_lb = pd.read_csv(DATA_DIR/'train_label_data.csv')\n",
    "sample = pd.read_csv(DATA_DIR/'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a3051",
   "metadata": {},
   "source": [
    "## 1 â€“ Data cleaning helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9f4686b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data preprocessed - Train: (130854, 21), Test: (21098, 21)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 2. ADVANCED DATA PREPROCESSING\n",
    "# ================================\n",
    "\n",
    "def preprocess_transactions(df):\n",
    "    \"\"\"Advanced transaction preprocessing\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Handle missing values more intelligently\n",
    "    df['PricePerUnit'] = df['PricePerUnit'].fillna(df.groupby('FK_PRODUCT_ID')['PricePerUnit'].transform('median'))\n",
    "    df['PricePerUnit'] = df['PricePerUnit'].fillna(df['PricePerUnit'].median())\n",
    "    \n",
    "    # Fix quantity issues\n",
    "    df['Qty'] = pd.to_numeric(df['Qty'], errors='coerce').fillna(1).astype(int)\n",
    "    df['Qty'] = df['Qty'].clip(lower=1, upper=50)  # Remove extreme outliers\n",
    "    \n",
    "    # Calculate amount\n",
    "    df['Amount'] = df['Qty'] * df['PricePerUnit']\n",
    "    \n",
    "    # Convert IDs to string for consistent merging\n",
    "    df['FK_PRODUCT_ID'] = df['FK_PRODUCT_ID'].astype(str)\n",
    "    df['FK_PROD_GRAM_ID'] = df['FK_PROD_GRAM_ID'].astype(str)\n",
    "    \n",
    "    # Extract time features\n",
    "    df['Hour'] = df['TransactionDatetime'].dt.hour\n",
    "    df['DayOfWeek'] = df['TransactionDatetime'].dt.dayofweek\n",
    "    df['Month'] = df['TransactionDatetime'].dt.month\n",
    "    df['Quarter'] = df['TransactionDatetime'].dt.quarter\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Preprocess transactions\n",
    "train_trx = preprocess_transactions(train_trx)\n",
    "test_trx = preprocess_transactions(test_trx)\n",
    "\n",
    "# Fix product and program data types\n",
    "product['productID'] = product['productID'].astype(str)\n",
    "program['prodgramID'] = program['prodgramID'].astype(str)\n",
    "\n",
    "# Merge with product and program data\n",
    "train_trx = train_trx.merge(product, left_on='FK_PRODUCT_ID', right_on='productID', how='left')\n",
    "train_trx = train_trx.merge(program, left_on='FK_PROD_GRAM_ID', right_on='prodgramID', how='left')\n",
    "test_trx = test_trx.merge(product, left_on='FK_PRODUCT_ID', right_on='productID', how='left')\n",
    "test_trx = test_trx.merge(program, left_on='FK_PROD_GRAM_ID', right_on='prodgramID', how='left')\n",
    "\n",
    "print(f\"âœ… Data preprocessed - Train: {train_trx.shape}, Test: {test_trx.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa94fb42",
   "metadata": {},
   "source": [
    "## 2 â€“ Join product & program info ke transaksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1633e19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Creating advanced features ...\n",
      "âœ… Created 31 features for 40020 members\n",
      "ðŸ”„ Creating advanced features ...\n",
      "âœ… Created 31 features for 6381 members\n",
      "âœ… Feature shapes aligned. Train: (40020, 32), Test: (6381, 32)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 3. COMPREHENSIVE FEATURE ENGINEERING  âœ… FIXED\n",
    "# ================================\n",
    "\n",
    "def create_advanced_features(df, prefix=\"\"):\n",
    "    \"\"\"Create comprehensive transaction features\"\"\"\n",
    "    print(f\"ðŸ”„ Creating advanced features ...\")\n",
    "    \n",
    "    df = df.copy()\n",
    "\n",
    "    # ===== Basic aggregations =====\n",
    "    basic_aggs = {\n",
    "        'TransactionID': 'nunique',\n",
    "        'Qty'         : ['sum', 'mean', 'std', 'max', 'min'],\n",
    "        'Amount'      : ['sum', 'mean', 'std', 'max', 'min'],\n",
    "        'PricePerUnit': ['mean', 'std', 'max', 'min'],\n",
    "        'FK_PRODUCT_ID': 'nunique',\n",
    "        'Source'       : 'nunique',\n",
    "        'Hour'         : ['mean', 'std'],\n",
    "        'DayOfWeek'    : ['mean', 'std'],\n",
    "        'Month'        : 'nunique',\n",
    "        'TransactionDatetime': ['min', 'max', 'count']\n",
    "    }\n",
    "\n",
    "    features = df.groupby('MemberID').agg(basic_aggs)\n",
    "    features.columns = [\n",
    "        f\"{prefix}{col[0]}_{col[1]}\" if isinstance(col, tuple) else f\"{prefix}{col}\"\n",
    "        for col in features.columns\n",
    "    ]\n",
    "\n",
    "    # ===== Time-based features =====\n",
    "    max_date = df['TransactionDatetime'].max()\n",
    "    features[f'{prefix}recency_days'] = (max_date - features[f'{prefix}TransactionDatetime_max']).dt.days\n",
    "    features[f'{prefix}span_days']    = (features[f'{prefix}TransactionDatetime_max'] -\n",
    "                                         features[f'{prefix}TransactionDatetime_min']).dt.days\n",
    "    features[f'{prefix}frequency']    = features[f'{prefix}TransactionDatetime_count'] / (\n",
    "                                         features[f'{prefix}span_days'] + 1)\n",
    "\n",
    "    # ===== Behavioral features =====\n",
    "    features[f'{prefix}avg_basket_size'] = features[f'{prefix}Amount_sum'] / features[f'{prefix}TransactionID_nunique']\n",
    "    features[f'{prefix}price_consistency'] = features[f'{prefix}PricePerUnit_std'] / (features[f'{prefix}PricePerUnit_mean'] + 1)\n",
    "    features[f'{prefix}qty_consistency']   = features[f'{prefix}Qty_std'] / (features[f'{prefix}Qty_mean'] + 1)\n",
    "\n",
    "    # ===== Category-level features (jika ada) =====\n",
    "    if 'ProductCategory' in df.columns:\n",
    "        cat_feat = df.groupby('MemberID')['ProductCategory'].agg(['nunique']).add_prefix(f'{prefix}category_')\n",
    "        features = features.join(cat_feat)\n",
    "\n",
    "    if 'ProductLevel' in df.columns:\n",
    "        lvl_feat = df.groupby('MemberID')['ProductLevel'].agg(['nunique']).add_prefix(f'{prefix}level_')\n",
    "        features = features.join(lvl_feat)\n",
    "\n",
    "    # ===== Source diversity =====\n",
    "    if 'Source' in df.columns:\n",
    "        source_entropy = df.groupby('MemberID')['Source'].apply(\n",
    "            lambda x: -np.sum((x.value_counts(normalize=True) * np.log(x.value_counts(normalize=True) + 1e-10)))\n",
    "        ).rename(f'{prefix}source_entropy')\n",
    "        features = features.join(source_entropy)\n",
    "\n",
    "    # Drop intermediate datetime cols & fill NA\n",
    "    datetime_cols = [c for c in features.columns if 'TransactionDatetime' in c]\n",
    "    features = features.drop(columns=datetime_cols).fillna(0)\n",
    "\n",
    "    print(f\"âœ… Created {features.shape[1]} features for {features.shape[0]} members\")\n",
    "    return features.reset_index()\n",
    "\n",
    "# ======= ðŸ”§ FIX: gunakan prefix YANG SAMA (kosong) untuk train & test =======\n",
    "train_features = create_advanced_features(train_trx, prefix=\"\")\n",
    "test_features  = create_advanced_features(test_trx,  prefix=\"\")\n",
    "\n",
    "print(f\"âœ… Feature shapes aligned. Train: {train_features.shape}, Test: {test_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b4045",
   "metadata": {},
   "source": [
    "## 3 â€“ Feature engineering (transaction â†’ member level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25337c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Creating enhanced member features...\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 4. ENHANCED MEMBER DEMOGRAPHICS\n",
    "# ================================\n",
    "\n",
    "def create_member_features(member_df):\n",
    "    \"\"\"Create enhanced member demographic features\"\"\"\n",
    "    print(\"ðŸ”„ Creating enhanced member features...\")\n",
    "    \n",
    "    df = member_df.copy()\n",
    "    reference_date = pd.Timestamp('2020-07-01')\n",
    "    \n",
    "    # Age calculations with better handling\n",
    "    df['MemberAge'] = (reference_date - df['DateOfBirth']).dt.days / 365.25\n",
    "    df['MemberAge'] = df['MemberAge'].clip(0, 100).fillna(df['MemberAge'].median())\n",
    "    \n",
    "    # Membership duration\n",
    "    df['MemberSeniority_days'] = (reference_date - df['JoinDate']).dt.days\n",
    "    df['MemberSeniority_months'] = df['MemberSeniority_days'] / 30.44\n",
    "    \n",
    "    # Children features\n",
    "    df['NoOfChild'] = df['NoOfChild'].fillna(0).astype(int)\n",
    "    df['HasChildren'] = (df['NoOfChild'] > 0).astype(int)\n",
    "    \n",
    "    # Age group categorization\n",
    "    df['AgeGroup'] = pd.cut(df['MemberAge'], \n",
    "                           bins=[0, 25, 35, 45, 55, 100], \n",
    "                           labels=['Young', 'YoungAdult', 'MiddleAge', 'Mature', 'Senior'])\n",
    "    \n",
    "    # City encoding with frequency\n",
    "    city_counts = df['City'].value_counts()\n",
    "    df['CityFrequency'] = df['City'].map(city_counts)\n",
    "    df['CityTier'] = pd.cut(df['CityFrequency'], \n",
    "                           bins=[0, 100, 500, 1000, 10000], \n",
    "                           labels=['SmallCity', 'MediumCity', 'LargeCity', 'MegaCity'])\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le_city = LabelEncoder()\n",
    "    df['City_encoded'] = le_city.fit_transform(df['City'].fillna('Unknown'))\n",
    "    \n",
    "    le_age_group = LabelEncoder()\n",
    "    df['AgeGroup_encoded'] = le_age_group.fit_transform(df['AgeGroup'].astype(str))\n",
    "    \n",
    "    le_city_tier = LabelEncoder()\n",
    "    df['CityTier_encoded'] = le_city_tier.fit_transform(df['CityTier'].astype(str))\n",
    "    \n",
    "    # Select final features\n",
    "    feature_cols = ['MemberID', 'MemberAge', 'MemberSeniority_days', 'MemberSeniority_months',\n",
    "                   'NoOfChild', 'HasChildren', 'CityFrequency', 'City_encoded', \n",
    "                   'AgeGroup_encoded', 'CityTier_encoded']\n",
    "    \n",
    "    return df[feature_cols].fillna(0)\n",
    "\n",
    "member_features = create_member_features(member)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe4319fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Assembling final dataset...\n",
      "âœ… Final dataset shapes:\n",
      "Training: (40020, 40), Target: (40020,)\n",
      "Test: (6381, 40)\n",
      "Target distribution: {0: 37582, 1: 2438}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 5. DATASET ASSEMBLY\n",
    "# ================================\n",
    "\n",
    "print(\"ðŸ”„ Assembling final dataset...\")\n",
    "\n",
    "# Merge training data\n",
    "train_df = train_lb.merge(train_features, on='MemberID', how='left')\n",
    "train_df = train_df.merge(member_features, on='MemberID', how='left')\n",
    "\n",
    "# Merge test data  \n",
    "test_df = sample[['MemberID']].merge(test_features, on='MemberID', how='left')\n",
    "test_df = test_df.merge(member_features, on='MemberID', how='left')\n",
    "\n",
    "# Fill remaining missing values\n",
    "train_df = train_df.fillna(0)\n",
    "test_df = test_df.fillna(0)\n",
    "\n",
    "# Create feature matrix\n",
    "X = train_df.drop(columns=['MemberID', 'next_buy'])\n",
    "y = train_df['next_buy']\n",
    "test_X = test_df.drop(columns=['MemberID'])\n",
    "\n",
    "print(f\"âœ… Final dataset shapes:\")\n",
    "print(f\"Training: {X.shape}, Target: {y.shape}\")\n",
    "print(f\"Test: {test_X.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8581acb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 22:25:30,362] A new study created in memory with name: enhanced_lgb_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting enhanced hyperparameter optimization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0707eea96d2c4122adc005e825f7792c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 22:25:42,945] Trial 0 finished with value: 0.8660650614733528 and parameters: {'learning_rate': 0.11051272527046793, 'num_leaves': 201, 'min_data_in_leaf': 10, 'feature_fraction': 0.736992007312699, 'bagging_fraction': 0.7913662737877938, 'bagging_freq': 2, 'lambda_l1': 1.329086346108448, 'lambda_l2': 7.762039690223464, 'min_gain_to_split': 0.15429203422932836, 'max_depth': 11}. Best is trial 0 with value: 0.8660650614733528.\n",
      "[I 2025-07-01 22:25:45,240] Trial 1 finished with value: 0.8369284858504678 and parameters: {'learning_rate': 0.14146911497724704, 'num_leaves': 127, 'min_data_in_leaf': 149, 'feature_fraction': 0.6339084207099448, 'bagging_fraction': 0.8268094334899073, 'bagging_freq': 2, 'lambda_l1': 1.657554723183745, 'lambda_l2': 9.674601250480897, 'min_gain_to_split': 0.9604402669005908, 'max_depth': 8}. Best is trial 0 with value: 0.8660650614733528.\n",
      "[I 2025-07-01 22:25:47,410] Trial 2 finished with value: 0.871227174006321 and parameters: {'learning_rate': 0.05975983749212784, 'num_leaves': 20, 'min_data_in_leaf': 88, 'feature_fraction': 0.8215040955665462, 'bagging_fraction': 0.8531212101266933, 'bagging_freq': 10, 'lambda_l1': 4.0345452516322915, 'lambda_l2': 9.396758105644734, 'min_gain_to_split': 0.5575962030297054, 'max_depth': 11}. Best is trial 2 with value: 0.871227174006321.\n",
      "[I 2025-07-01 22:25:50,386] Trial 3 finished with value: 0.8783021457938138 and parameters: {'learning_rate': 0.01401749300542483, 'num_leaves': 201, 'min_data_in_leaf': 266, 'feature_fraction': 0.7251397265299526, 'bagging_fraction': 0.8508287565705697, 'bagging_freq': 6, 'lambda_l1': 3.848409423658401, 'lambda_l2': 4.660048798146504, 'min_gain_to_split': 0.5674931416094079, 'max_depth': 10}. Best is trial 3 with value: 0.8783021457938138.\n",
      "[I 2025-07-01 22:25:58,847] Trial 4 finished with value: 0.8660876316580607 and parameters: {'learning_rate': 0.18244179470611194, 'num_leaves': 502, 'min_data_in_leaf': 132, 'feature_fraction': 0.43837481411807105, 'bagging_fraction': 0.9277417887283153, 'bagging_freq': 5, 'lambda_l1': 4.609122410974543, 'lambda_l2': 2.2726256666359, 'min_gain_to_split': 0.1632265170777376, 'max_depth': 15}. Best is trial 3 with value: 0.8783021457938138.\n",
      "[I 2025-07-01 22:26:00,497] Trial 5 finished with value: 0.8376509913154117 and parameters: {'learning_rate': 0.1838378061636245, 'num_leaves': 126, 'min_data_in_leaf': 230, 'feature_fraction': 0.7020701953183768, 'bagging_fraction': 0.5028742555748142, 'bagging_freq': 9, 'lambda_l1': 8.4854897185039, 'lambda_l2': 8.188841376843634, 'min_gain_to_split': 0.3150721916711121, 'max_depth': 5}. Best is trial 3 with value: 0.8783021457938138.\n",
      "[I 2025-07-01 22:26:02,928] Trial 6 finished with value: 0.8680479378251473 and parameters: {'learning_rate': 0.014333556518037133, 'num_leaves': 410, 'min_data_in_leaf': 255, 'feature_fraction': 0.45409744546387343, 'bagging_fraction': 0.8448411888349796, 'bagging_freq': 6, 'lambda_l1': 5.4162933052610285, 'lambda_l2': 1.43039806551159, 'min_gain_to_split': 0.6890828111022065, 'max_depth': 7}. Best is trial 3 with value: 0.8783021457938138.\n",
      "[I 2025-07-01 22:26:06,663] Trial 7 finished with value: 0.8755320282425361 and parameters: {'learning_rate': 0.01832397384195373, 'num_leaves': 280, 'min_data_in_leaf': 170, 'feature_fraction': 0.713022255394313, 'bagging_fraction': 0.7949079845845861, 'bagging_freq': 1, 'lambda_l1': 1.1500718957332856, 'lambda_l2': 0.7489358464371076, 'min_gain_to_split': 0.03449328185636613, 'max_depth': 13}. Best is trial 3 with value: 0.8783021457938138.\n",
      "[I 2025-07-01 22:26:11,273] Trial 8 finished with value: 0.872876863710953 and parameters: {'learning_rate': 0.07545346038945415, 'num_leaves': 490, 'min_data_in_leaf': 52, 'feature_fraction': 0.7995822658680528, 'bagging_fraction': 0.9293403295753669, 'bagging_freq': 4, 'lambda_l1': 5.420769282810605, 'lambda_l2': 5.540021045042578, 'min_gain_to_split': 0.09136579279834711, 'max_depth': 14}. Best is trial 3 with value: 0.8783021457938138.\n",
      "[I 2025-07-01 22:26:13,485] Trial 9 finished with value: 0.8565803705650117 and parameters: {'learning_rate': 0.14628693361363243, 'num_leaves': 442, 'min_data_in_leaf': 254, 'feature_fraction': 0.7952570267789771, 'bagging_fraction': 0.9612273790508506, 'bagging_freq': 10, 'lambda_l1': 5.113985526207222, 'lambda_l2': 2.009577695135656, 'min_gain_to_split': 0.07098079087924913, 'max_depth': 6}. Best is trial 3 with value: 0.8783021457938138.\n",
      "[I 2025-07-01 22:26:15,114] Trial 10 finished with value: 0.8760159287328806 and parameters: {'learning_rate': 0.02936825377861007, 'num_leaves': 309, 'min_data_in_leaf': 283, 'feature_fraction': 0.9649086520318331, 'bagging_fraction': 0.6369525631084473, 'bagging_freq': 7, 'lambda_l1': 9.941031764368669, 'lambda_l2': 4.91211216596989, 'min_gain_to_split': 0.8464784728381055, 'max_depth': 3}. Best is trial 3 with value: 0.8783021457938138.\n",
      "[I 2025-07-01 22:26:16,644] Trial 11 finished with value: 0.8750591956644973 and parameters: {'learning_rate': 0.026457192482869887, 'num_leaves': 315, 'min_data_in_leaf': 300, 'feature_fraction': 0.9894823988238078, 'bagging_fraction': 0.6179612979645228, 'bagging_freq': 7, 'lambda_l1': 9.735542442006572, 'lambda_l2': 4.356209860000209, 'min_gain_to_split': 0.8521006650384385, 'max_depth': 3}. Best is trial 3 with value: 0.8783021457938138.\n",
      "[I 2025-07-01 22:26:19,308] Trial 12 finished with value: 0.8809131177390823 and parameters: {'learning_rate': 0.03219278374338062, 'num_leaves': 346, 'min_data_in_leaf': 293, 'feature_fraction': 0.9876268451268126, 'bagging_fraction': 0.668898340313444, 'bagging_freq': 8, 'lambda_l1': 7.245291499168722, 'lambda_l2': 4.646606326851055, 'min_gain_to_split': 0.6862885510426093, 'max_depth': 10}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:22,735] Trial 13 finished with value: 0.8781830534627627 and parameters: {'learning_rate': 0.010257030564022164, 'num_leaves': 367, 'min_data_in_leaf': 205, 'feature_fraction': 0.5928851926887959, 'bagging_fraction': 0.7009016694989127, 'bagging_freq': 8, 'lambda_l1': 7.207531149843124, 'lambda_l2': 3.75894484463752, 'min_gain_to_split': 0.5122186669424168, 'max_depth': 10}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:24,965] Trial 14 finished with value: 0.8797333065356827 and parameters: {'learning_rate': 0.03530208279231029, 'num_leaves': 178, 'min_data_in_leaf': 200, 'feature_fraction': 0.9218181323018676, 'bagging_fraction': 0.48984301399756963, 'bagging_freq': 4, 'lambda_l1': 3.229990588059966, 'lambda_l2': 6.401949360525915, 'min_gain_to_split': 0.6698016551604142, 'max_depth': 9}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:27,226] Trial 15 finished with value: 0.8788718397581375 and parameters: {'learning_rate': 0.03735757986588958, 'num_leaves': 179, 'min_data_in_leaf': 202, 'feature_fraction': 0.8761870980885187, 'bagging_fraction': 0.41143647863058097, 'bagging_freq': 4, 'lambda_l1': 6.794482305306915, 'lambda_l2': 6.565316165697666, 'min_gain_to_split': 0.7059114464859362, 'max_depth': 12}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:30,639] Trial 16 finished with value: 0.8777329778298368 and parameters: {'learning_rate': 0.043236010705834736, 'num_leaves': 370, 'min_data_in_leaf': 113, 'feature_fraction': 0.9082004346786913, 'bagging_fraction': 0.5333029155960574, 'bagging_freq': 4, 'lambda_l1': 2.991988540596662, 'lambda_l2': 6.386787763677171, 'min_gain_to_split': 0.7041705119679227, 'max_depth': 9}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:33,822] Trial 17 finished with value: 0.879413021973904 and parameters: {'learning_rate': 0.023785101602390946, 'num_leaves': 24, 'min_data_in_leaf': 185, 'feature_fraction': 0.9087357460314882, 'bagging_fraction': 0.4009530376615171, 'bagging_freq': 8, 'lambda_l1': 6.823614936799228, 'lambda_l2': 3.5151503398194106, 'min_gain_to_split': 0.36467084865004107, 'max_depth': 8}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:35,749] Trial 18 finished with value: 0.8740112751658756 and parameters: {'learning_rate': 0.27267384814812673, 'num_leaves': 80, 'min_data_in_leaf': 227, 'feature_fraction': 0.972908025006262, 'bagging_fraction': 0.5141160878031822, 'bagging_freq': 3, 'lambda_l1': 2.6424747055754243, 'lambda_l2': 6.323362317719319, 'min_gain_to_split': 0.37654991860655934, 'max_depth': 5}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:38,374] Trial 19 finished with value: 0.8796339495686804 and parameters: {'learning_rate': 0.07520578619302482, 'num_leaves': 238, 'min_data_in_leaf': 224, 'feature_fraction': 0.8636314280575744, 'bagging_fraction': 0.7097258679798689, 'bagging_freq': 5, 'lambda_l1': 8.028617843700347, 'lambda_l2': 7.7374165372641235, 'min_gain_to_split': 0.8095049828315253, 'max_depth': 9}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:41,437] Trial 20 finished with value: 0.8751667251971978 and parameters: {'learning_rate': 0.04303745510515629, 'num_leaves': 257, 'min_data_in_leaf': 295, 'feature_fraction': 0.6110685335904735, 'bagging_fraction': 0.6027498651120483, 'bagging_freq': 7, 'lambda_l1': 0.25425487034394845, 'lambda_l2': 3.332141645096746, 'min_gain_to_split': 0.6112818785973166, 'max_depth': 12}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:44,359] Trial 21 finished with value: 0.880255728815802 and parameters: {'learning_rate': 0.06582419855323597, 'num_leaves': 257, 'min_data_in_leaf': 228, 'feature_fraction': 0.8643079731229281, 'bagging_fraction': 0.7066172601951927, 'bagging_freq': 5, 'lambda_l1': 8.62394771873184, 'lambda_l2': 7.664446596229706, 'min_gain_to_split': 0.821678493126845, 'max_depth': 9}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:47,112] Trial 22 finished with value: 0.8793016819669852 and parameters: {'learning_rate': 0.0611766405184799, 'num_leaves': 357, 'min_data_in_leaf': 242, 'feature_fraction': 0.9320198014214528, 'bagging_fraction': 0.7370516410498007, 'bagging_freq': 3, 'lambda_l1': 8.805545070861786, 'lambda_l2': 8.690729355221187, 'min_gain_to_split': 0.9714813377283362, 'max_depth': 8}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:49,670] Trial 23 finished with value: 0.880292267718708 and parameters: {'learning_rate': 0.03181185560696004, 'num_leaves': 153, 'min_data_in_leaf': 202, 'feature_fraction': 0.8442230650877608, 'bagging_fraction': 0.5649275358972439, 'bagging_freq': 5, 'lambda_l1': 6.242447285123999, 'lambda_l2': 6.973052430032599, 'min_gain_to_split': 0.7792452009421661, 'max_depth': 10}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:53,053] Trial 24 finished with value: 0.8771456631508603 and parameters: {'learning_rate': 0.088751850103155, 'num_leaves': 118, 'min_data_in_leaf': 167, 'feature_fraction': 0.8719583008139757, 'bagging_fraction': 0.6560032182051838, 'bagging_freq': 6, 'lambda_l1': 6.0145049517764715, 'lambda_l2': 7.142849182516459, 'min_gain_to_split': 0.783241372437302, 'max_depth': 11}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:55,883] Trial 25 finished with value: 0.8756214563258691 and parameters: {'learning_rate': 0.05101324170079394, 'num_leaves': 315, 'min_data_in_leaf': 268, 'feature_fraction': 0.7701356104258962, 'bagging_fraction': 0.5560270071803136, 'bagging_freq': 8, 'lambda_l1': 7.559819399047569, 'lambda_l2': 5.531398518170476, 'min_gain_to_split': 0.9142936968997276, 'max_depth': 10}. Best is trial 12 with value: 0.8809131177390823.\n",
      "[I 2025-07-01 22:26:58,978] Trial 26 finished with value: 0.8816941940168933 and parameters: {'learning_rate': 0.019386065214159313, 'num_leaves': 234, 'min_data_in_leaf': 276, 'feature_fraction': 0.8343825478055815, 'bagging_fraction': 0.5733172754456358, 'bagging_freq': 5, 'lambda_l1': 6.383125845304295, 'lambda_l2': 5.575737493192867, 'min_gain_to_split': 0.773840233891024, 'max_depth': 7}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:01,286] Trial 27 finished with value: 0.8793906061682438 and parameters: {'learning_rate': 0.018689537444870678, 'num_leaves': 73, 'min_data_in_leaf': 276, 'feature_fraction': 0.6540114151614276, 'bagging_fraction': 0.5730104952932348, 'bagging_freq': 9, 'lambda_l1': 6.458539012170461, 'lambda_l2': 5.656244089562379, 'min_gain_to_split': 0.7610228708802796, 'max_depth': 7}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:03,109] Trial 28 finished with value: 0.8771246761542196 and parameters: {'learning_rate': 0.022846795277247874, 'num_leaves': 225, 'min_data_in_leaf': 288, 'feature_fraction': 0.5453320262705377, 'bagging_fraction': 0.4511695693448969, 'bagging_freq': 6, 'lambda_l1': 6.080261299506381, 'lambda_l2': 2.5885149540513535, 'min_gain_to_split': 0.63568816086216, 'max_depth': 6}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:07,328] Trial 29 finished with value: 0.8768402154917174 and parameters: {'learning_rate': 0.031086512894522526, 'num_leaves': 164, 'min_data_in_leaf': 28, 'feature_fraction': 0.7596422315016231, 'bagging_fraction': 0.652376707496009, 'bagging_freq': 3, 'lambda_l1': 7.693682504470516, 'lambda_l2': 4.169277100139474, 'min_gain_to_split': 0.45948603565865986, 'max_depth': 12}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:09,911] Trial 30 finished with value: 0.8798042896299043 and parameters: {'learning_rate': 0.019468764875666445, 'num_leaves': 290, 'min_data_in_leaf': 247, 'feature_fraction': 0.8323439350856647, 'bagging_fraction': 0.756747707381541, 'bagging_freq': 5, 'lambda_l1': 5.973978968947179, 'lambda_l2': 7.032711003824379, 'min_gain_to_split': 0.9191836730722251, 'max_depth': 7}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:12,554] Trial 31 finished with value: 0.8792365821831541 and parameters: {'learning_rate': 0.04765699719894088, 'num_leaves': 216, 'min_data_in_leaf': 216, 'feature_fraction': 0.8461806758157303, 'bagging_fraction': 0.6752631088888313, 'bagging_freq': 5, 'lambda_l1': 8.583448217022477, 'lambda_l2': 7.762384727351424, 'min_gain_to_split': 0.7535053352296595, 'max_depth': 10}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:16,019] Trial 32 finished with value: 0.8763519536610047 and parameters: {'learning_rate': 0.10661631463953505, 'num_leaves': 340, 'min_data_in_leaf': 243, 'feature_fraction': 0.9490233994441258, 'bagging_fraction': 0.5783159006213235, 'bagging_freq': 5, 'lambda_l1': 8.918118543986637, 'lambda_l2': 8.66629037924516, 'min_gain_to_split': 0.8886968691131291, 'max_depth': 11}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:18,871] Trial 33 finished with value: 0.8805248360619439 and parameters: {'learning_rate': 0.03470063719562572, 'num_leaves': 252, 'min_data_in_leaf': 267, 'feature_fraction': 0.9995858340845725, 'bagging_fraction': 0.7541386358390246, 'bagging_freq': 7, 'lambda_l1': 9.305342591891193, 'lambda_l2': 5.662204994369235, 'min_gain_to_split': 0.9997323000910362, 'max_depth': 8}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:22,514] Trial 34 finished with value: 0.878256196302235 and parameters: {'learning_rate': 0.035795787594828404, 'num_leaves': 404, 'min_data_in_leaf': 281, 'feature_fraction': 0.9989843998118823, 'bagging_fraction': 0.7607897825910647, 'bagging_freq': 7, 'lambda_l1': 9.379580431685909, 'lambda_l2': 5.2452424105372515, 'min_gain_to_split': 0.9475836956372532, 'max_depth': 8}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:25,366] Trial 35 finished with value: 0.8801756033297012 and parameters: {'learning_rate': 0.014867761902156518, 'num_leaves': 149, 'min_data_in_leaf': 266, 'feature_fraction': 0.8922079088410915, 'bagging_fraction': 0.7979853106534058, 'bagging_freq': 9, 'lambda_l1': 4.585137560752024, 'lambda_l2': 5.864247257381078, 'min_gain_to_split': 0.9814166730364665, 'max_depth': 6}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:27,992] Trial 36 finished with value: 0.878469154965645 and parameters: {'learning_rate': 0.010924243298158881, 'num_leaves': 201, 'min_data_in_leaf': 141, 'feature_fraction': 0.6738444546157424, 'bagging_fraction': 0.6078960907146592, 'bagging_freq': 8, 'lambda_l1': 7.812205769927398, 'lambda_l2': 4.907035320862557, 'min_gain_to_split': 0.5942640931487976, 'max_depth': 8}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:29,680] Trial 37 finished with value: 0.8802535209838943 and parameters: {'learning_rate': 0.02169114869078178, 'num_leaves': 249, 'min_data_in_leaf': 262, 'feature_fraction': 0.9537325678170135, 'bagging_fraction': 0.4620402994471686, 'bagging_freq': 6, 'lambda_l1': 7.125029636327823, 'lambda_l2': 3.0930497434616013, 'min_gain_to_split': 0.5060712565349422, 'max_depth': 5}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:33,005] Trial 38 finished with value: 0.8803221990514626 and parameters: {'learning_rate': 0.027902431340678567, 'num_leaves': 277, 'min_data_in_leaf': 184, 'feature_fraction': 0.7513958791186433, 'bagging_fraction': 0.8852081742947713, 'bagging_freq': 7, 'lambda_l1': 4.194559864686195, 'lambda_l2': 4.312448725953965, 'min_gain_to_split': 0.9984899409178527, 'max_depth': 11}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:37,328] Trial 39 finished with value: 0.880939390495195 and parameters: {'learning_rate': 0.02574031377703695, 'num_leaves': 279, 'min_data_in_leaf': 105, 'feature_fraction': 0.7470524587766401, 'bagging_fraction': 0.8849323502954081, 'bagging_freq': 7, 'lambda_l1': 3.9568199140814273, 'lambda_l2': 4.339967453548844, 'min_gain_to_split': 0.9969558632694329, 'max_depth': 13}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:41,924] Trial 40 finished with value: 0.8800621562965143 and parameters: {'learning_rate': 0.016029531979320243, 'num_leaves': 405, 'min_data_in_leaf': 86, 'feature_fraction': 0.7995964255024318, 'bagging_fraction': 0.994134438982833, 'bagging_freq': 9, 'lambda_l1': 3.6323601287911242, 'lambda_l2': 3.9431953544972735, 'min_gain_to_split': 0.9226555756768988, 'max_depth': 15}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:46,200] Trial 41 finished with value: 0.8807363053339328 and parameters: {'learning_rate': 0.02767488351990336, 'num_leaves': 278, 'min_data_in_leaf': 96, 'feature_fraction': 0.7316009189971819, 'bagging_fraction': 0.9055361361135343, 'bagging_freq': 7, 'lambda_l1': 4.246202891014389, 'lambda_l2': 4.560157033085067, 'min_gain_to_split': 0.978309170764196, 'max_depth': 13}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:50,894] Trial 42 finished with value: 0.8774513956598262 and parameters: {'learning_rate': 0.012467514099034273, 'num_leaves': 287, 'min_data_in_leaf': 89, 'feature_fraction': 0.6844959344028189, 'bagging_fraction': 0.8831119781295879, 'bagging_freq': 8, 'lambda_l1': 2.0935520811600696, 'lambda_l2': 4.9585968177935245, 'min_gain_to_split': 0.8640941100858872, 'max_depth': 14}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:55,214] Trial 43 finished with value: 0.8785465906696356 and parameters: {'learning_rate': 0.025298643193410603, 'num_leaves': 332, 'min_data_in_leaf': 117, 'feature_fraction': 0.7352295533090193, 'bagging_fraction': 0.8232157021669977, 'bagging_freq': 7, 'lambda_l1': 5.494359039863751, 'lambda_l2': 4.599882643598179, 'min_gain_to_split': 0.9461793379702661, 'max_depth': 13}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:27:59,703] Trial 44 finished with value: 0.879363588349921 and parameters: {'learning_rate': 0.02057526941357805, 'num_leaves': 299, 'min_data_in_leaf': 68, 'feature_fraction': 0.7041856239732719, 'bagging_fraction': 0.8882499104183729, 'bagging_freq': 10, 'lambda_l1': 4.597808078478748, 'lambda_l2': 5.882530601056854, 'min_gain_to_split': 0.887091048491298, 'max_depth': 14}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:04,069] Trial 45 finished with value: 0.8763257842075534 and parameters: {'learning_rate': 0.017108542515034592, 'num_leaves': 231, 'min_data_in_leaf': 114, 'feature_fraction': 0.5587006044881068, 'bagging_fraction': 0.9287627897786689, 'bagging_freq': 6, 'lambda_l1': 3.580155615850444, 'lambda_l2': 2.939816876268254, 'min_gain_to_split': 0.20852924445843213, 'max_depth': 13}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:06,171] Trial 46 finished with value: 0.8738065865530398 and parameters: {'learning_rate': 0.04006578845339817, 'num_leaves': 267, 'min_data_in_leaf': 58, 'feature_fraction': 0.7943028127445302, 'bagging_fraction': 0.8221878970580697, 'bagging_freq': 7, 'lambda_l1': 4.970367735293435, 'lambda_l2': 5.168231057894432, 'min_gain_to_split': 0.9955625807504178, 'max_depth': 4}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:11,058] Trial 47 finished with value: 0.8766974832501004 and parameters: {'learning_rate': 0.03276998510090202, 'num_leaves': 200, 'min_data_in_leaf': 95, 'feature_fraction': 0.7307365088143052, 'bagging_fraction': 0.9655550303987581, 'bagging_freq': 9, 'lambda_l1': 5.166316600162897, 'lambda_l2': 0.26910770813579266, 'min_gain_to_split': 0.8319409185494334, 'max_depth': 15}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:14,386] Trial 48 finished with value: 0.8710848587038278 and parameters: {'learning_rate': 0.028158198401315882, 'num_leaves': 445, 'min_data_in_leaf': 133, 'feature_fraction': 0.47514519745406325, 'bagging_fraction': 0.8966388797069368, 'bagging_freq': 8, 'lambda_l1': 8.242842321419271, 'lambda_l2': 4.562339661634459, 'min_gain_to_split': 0.7307292500390524, 'max_depth': 7}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:19,012] Trial 49 finished with value: 0.8807050755157384 and parameters: {'learning_rate': 0.013435517775681725, 'num_leaves': 338, 'min_data_in_leaf': 155, 'feature_fraction': 0.9741907361267486, 'bagging_fraction': 0.8645972427226456, 'bagging_freq': 6, 'lambda_l1': 4.111103188358642, 'lambda_l2': 3.7891077268870164, 'min_gain_to_split': 0.8895304931287267, 'max_depth': 12}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:23,670] Trial 50 finished with value: 0.8801349736856572 and parameters: {'learning_rate': 0.012558954730570933, 'num_leaves': 382, 'min_data_in_leaf': 150, 'feature_fraction': 0.8225273265930828, 'bagging_fraction': 0.8494460101215993, 'bagging_freq': 6, 'lambda_l1': 4.180823533817997, 'lambda_l2': 1.7088048086643113, 'min_gain_to_split': 0.6715590117240002, 'max_depth': 12}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:28,648] Trial 51 finished with value: 0.8797870205150332 and parameters: {'learning_rate': 0.024661858264175513, 'num_leaves': 338, 'min_data_in_leaf': 101, 'feature_fraction': 0.984099644927145, 'bagging_fraction': 0.8651659211696978, 'bagging_freq': 7, 'lambda_l1': 2.527560346651173, 'lambda_l2': 3.9045635081278682, 'min_gain_to_split': 0.8934833618737976, 'max_depth': 14}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:32,889] Trial 52 finished with value: 0.880320227522813 and parameters: {'learning_rate': 0.012856343701370001, 'num_leaves': 320, 'min_data_in_leaf': 161, 'feature_fraction': 0.9446349169175371, 'bagging_fraction': 0.9139212147552581, 'bagging_freq': 6, 'lambda_l1': 3.8425983070111283, 'lambda_l2': 3.422468592312443, 'min_gain_to_split': 0.9482685986716815, 'max_depth': 13}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:37,993] Trial 53 finished with value: 0.8784926713466854 and parameters: {'learning_rate': 0.01663712457068197, 'num_leaves': 268, 'min_data_in_leaf': 75, 'feature_fraction': 0.9778185166291615, 'bagging_fraction': 0.953083701071344, 'bagging_freq': 8, 'lambda_l1': 5.5728878433234375, 'lambda_l2': 6.0150421830753675, 'min_gain_to_split': 0.8755943822331866, 'max_depth': 13}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:42,467] Trial 54 finished with value: 0.880349977353986 and parameters: {'learning_rate': 0.021050345002713272, 'num_leaves': 348, 'min_data_in_leaf': 35, 'feature_fraction': 0.9112182567421417, 'bagging_fraction': 0.7354568068827593, 'bagging_freq': 7, 'lambda_l1': 3.2066156589009864, 'lambda_l2': 5.350102619934128, 'min_gain_to_split': 0.8171580827416733, 'max_depth': 11}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:45,909] Trial 55 finished with value: 0.8777078945854957 and parameters: {'learning_rate': 0.038502934903742944, 'num_leaves': 300, 'min_data_in_leaf': 126, 'feature_fraction': 0.9999904982817243, 'bagging_fraction': 0.7934553605518343, 'bagging_freq': 7, 'lambda_l1': 9.255492090576112, 'lambda_l2': 3.8027378217552896, 'min_gain_to_split': 0.9478697797446982, 'max_depth': 12}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:48,954] Trial 56 finished with value: 0.8795893606022119 and parameters: {'learning_rate': 0.028066913729835906, 'num_leaves': 378, 'min_data_in_leaf': 295, 'feature_fraction': 0.9335330779379442, 'bagging_fraction': 0.6793680524171266, 'bagging_freq': 1, 'lambda_l1': 4.403785750622292, 'lambda_l2': 4.753840913398085, 'min_gain_to_split': 0.85193680313007, 'max_depth': 9}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:52,528] Trial 57 finished with value: 0.8776696975937842 and parameters: {'learning_rate': 0.05613153927094961, 'num_leaves': 241, 'min_data_in_leaf': 276, 'feature_fraction': 0.7812070525073974, 'bagging_fraction': 0.8662420527264129, 'bagging_freq': 6, 'lambda_l1': 4.8467292586754205, 'lambda_l2': 2.6597165614400815, 'min_gain_to_split': 0.8010346060083733, 'max_depth': 14}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:28:55,739] Trial 58 finished with value: 0.8812315861232684 and parameters: {'learning_rate': 0.01443740849783505, 'num_leaves': 208, 'min_data_in_leaf': 256, 'feature_fraction': 0.9589916529659079, 'bagging_fraction': 0.7681126257866776, 'bagging_freq': 4, 'lambda_l1': 6.8521789028639155, 'lambda_l2': 4.265654805530451, 'min_gain_to_split': 0.7284946989016425, 'max_depth': 13}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:29:01,253] Trial 59 finished with value: 0.8804252289064131 and parameters: {'learning_rate': 0.010020640255077378, 'num_leaves': 205, 'min_data_in_leaf': 104, 'feature_fraction': 0.9041277607251468, 'bagging_fraction': 0.8382199155216056, 'bagging_freq': 2, 'lambda_l1': 6.658913982546002, 'lambda_l2': 4.23879709453698, 'min_gain_to_split': 0.640757335884886, 'max_depth': 12}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:29:05,487] Trial 60 finished with value: 0.8805673954863866 and parameters: {'learning_rate': 0.01455779797566397, 'num_leaves': 456, 'min_data_in_leaf': 190, 'feature_fraction': 0.9601943177966693, 'bagging_fraction': 0.7780741432364896, 'bagging_freq': 4, 'lambda_l1': 7.343401352944909, 'lambda_l2': 3.608993412099518, 'min_gain_to_split': 0.5593886680146242, 'max_depth': 13}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:29:09,868] Trial 61 finished with value: 0.8813755289622064 and parameters: {'learning_rate': 0.014303098552940322, 'num_leaves': 482, 'min_data_in_leaf': 173, 'feature_fraction': 0.9659524761434761, 'bagging_fraction': 0.8118262147397851, 'bagging_freq': 4, 'lambda_l1': 7.214560037178384, 'lambda_l2': 3.532433371152979, 'min_gain_to_split': 0.5617255569374421, 'max_depth': 13}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:29:13,409] Trial 62 finished with value: 0.8801245500218189 and parameters: {'learning_rate': 0.01753286656619419, 'num_leaves': 512, 'min_data_in_leaf': 254, 'feature_fraction': 0.8895178210543468, 'bagging_fraction': 0.8070986049944058, 'bagging_freq': 3, 'lambda_l1': 6.959829128952349, 'lambda_l2': 9.991552072301873, 'min_gain_to_split': 0.7349649945608593, 'max_depth': 14}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:29:17,883] Trial 63 finished with value: 0.881343241021342 and parameters: {'learning_rate': 0.011745685112469161, 'num_leaves': 493, 'min_data_in_leaf': 175, 'feature_fraction': 0.9757608266633793, 'bagging_fraction': 0.9106634064150765, 'bagging_freq': 4, 'lambda_l1': 6.717777452735823, 'lambda_l2': 3.128809464914315, 'min_gain_to_split': 0.4671882453654291, 'max_depth': 13}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:29:22,022] Trial 64 finished with value: 0.8813724653685296 and parameters: {'learning_rate': 0.011990385930287003, 'num_leaves': 474, 'min_data_in_leaf': 175, 'feature_fraction': 0.919963666805781, 'bagging_fraction': 0.7280240207381024, 'bagging_freq': 4, 'lambda_l1': 6.421003550915341, 'lambda_l2': 3.1012165680386152, 'min_gain_to_split': 0.4553562276803001, 'max_depth': 13}. Best is trial 26 with value: 0.8816941940168933.\n",
      "[I 2025-07-01 22:29:26,111] Trial 65 finished with value: 0.8817765054852522 and parameters: {'learning_rate': 0.011670326136750425, 'num_leaves': 480, 'min_data_in_leaf': 176, 'feature_fraction': 0.931829088941176, 'bagging_fraction': 0.7269453477612038, 'bagging_freq': 4, 'lambda_l1': 6.346493672191963, 'lambda_l2': 2.0803251740715973, 'min_gain_to_split': 0.4511626087733003, 'max_depth': 15}. Best is trial 65 with value: 0.8817765054852522.\n",
      "[I 2025-07-01 22:29:30,153] Trial 66 finished with value: 0.8809026472094075 and parameters: {'learning_rate': 0.011507878481621504, 'num_leaves': 471, 'min_data_in_leaf': 169, 'feature_fraction': 0.9269708334674971, 'bagging_fraction': 0.7244823869852285, 'bagging_freq': 4, 'lambda_l1': 5.795378756139356, 'lambda_l2': 1.104618680818707, 'min_gain_to_split': 0.4534955756082149, 'max_depth': 15}. Best is trial 65 with value: 0.8817765054852522.\n",
      "[I 2025-07-01 22:29:34,082] Trial 67 finished with value: 0.8815852014173334 and parameters: {'learning_rate': 0.01148954135757822, 'num_leaves': 488, 'min_data_in_leaf': 178, 'feature_fraction': 0.8843605449768394, 'bagging_fraction': 0.7254320182831645, 'bagging_freq': 4, 'lambda_l1': 6.534675867553818, 'lambda_l2': 2.1681914703728635, 'min_gain_to_split': 0.3877623270714564, 'max_depth': 15}. Best is trial 65 with value: 0.8817765054852522.\n",
      "[I 2025-07-01 22:29:37,678] Trial 68 finished with value: 0.8812631367368848 and parameters: {'learning_rate': 0.011380052315718363, 'num_leaves': 487, 'min_data_in_leaf': 180, 'feature_fraction': 0.8819322576186734, 'bagging_fraction': 0.6933388760300253, 'bagging_freq': 4, 'lambda_l1': 6.305696339060756, 'lambda_l2': 2.3194168729239935, 'min_gain_to_split': 0.3948172120169228, 'max_depth': 14}. Best is trial 65 with value: 0.8817765054852522.\n",
      "[I 2025-07-01 22:29:40,983] Trial 69 finished with value: 0.8817382868023771 and parameters: {'learning_rate': 0.011851263348801166, 'num_leaves': 486, 'min_data_in_leaf': 175, 'feature_fraction': 0.8544107826439792, 'bagging_fraction': 0.6841722953689146, 'bagging_freq': 3, 'lambda_l1': 6.382904262997389, 'lambda_l2': 2.1600149004851508, 'min_gain_to_split': 0.38003477961295307, 'max_depth': 15}. Best is trial 65 with value: 0.8817765054852522.\n",
      "[I 2025-07-01 22:29:43,818] Trial 70 finished with value: 0.8813208220593628 and parameters: {'learning_rate': 0.011372416433179792, 'num_leaves': 488, 'min_data_in_leaf': 211, 'feature_fraction': 0.840222939840316, 'bagging_fraction': 0.6290262963938029, 'bagging_freq': 3, 'lambda_l1': 6.625941127772514, 'lambda_l2': 1.9176634720022676, 'min_gain_to_split': 0.2843302889726147, 'max_depth': 15}. Best is trial 65 with value: 0.8817765054852522.\n",
      "[I 2025-07-01 22:29:47,204] Trial 71 finished with value: 0.8821519231182885 and parameters: {'learning_rate': 0.011710556955769997, 'num_leaves': 487, 'min_data_in_leaf': 177, 'feature_fraction': 0.8641050508298302, 'bagging_fraction': 0.6379813564261645, 'bagging_freq': 3, 'lambda_l1': 6.470615057588148, 'lambda_l2': 2.1244355495954323, 'min_gain_to_split': 0.27681932093474737, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:29:50,253] Trial 72 finished with value: 0.8804607313407529 and parameters: {'learning_rate': 0.015552548307309719, 'num_leaves': 471, 'min_data_in_leaf': 192, 'feature_fraction': 0.8557026682014869, 'bagging_fraction': 0.6474954615815318, 'bagging_freq': 2, 'lambda_l1': 7.419421924080055, 'lambda_l2': 1.1224665782010201, 'min_gain_to_split': 0.2882298770969344, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:29:53,422] Trial 73 finished with value: 0.8814150900899227 and parameters: {'learning_rate': 0.010810484821373282, 'num_leaves': 428, 'min_data_in_leaf': 177, 'feature_fraction': 0.9175442470214595, 'bagging_fraction': 0.5971734890795403, 'bagging_freq': 3, 'lambda_l1': 6.416943307056937, 'lambda_l2': 2.3068469266437637, 'min_gain_to_split': 0.4351782306237874, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:29:56,691] Trial 74 finished with value: 0.880247077668389 and parameters: {'learning_rate': 0.010117976510302818, 'num_leaves': 420, 'min_data_in_leaf': 192, 'feature_fraction': 0.9017510837224473, 'bagging_fraction': 0.5459970460357, 'bagging_freq': 3, 'lambda_l1': 5.776015841383325, 'lambda_l2': 2.0873001291131468, 'min_gain_to_split': 0.3434226914461095, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:29:59,938] Trial 75 finished with value: 0.882039099534963 and parameters: {'learning_rate': 0.013607454763887004, 'num_leaves': 424, 'min_data_in_leaf': 162, 'feature_fraction': 0.8724512138868101, 'bagging_fraction': 0.5915755100782846, 'bagging_freq': 2, 'lambda_l1': 6.356723191803894, 'lambda_l2': 1.577337310603803, 'min_gain_to_split': 0.41628676719048596, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:03,097] Trial 76 finished with value: 0.8818577662800318 and parameters: {'learning_rate': 0.013414603167588749, 'num_leaves': 425, 'min_data_in_leaf': 144, 'feature_fraction': 0.8128514911574405, 'bagging_fraction': 0.6164946056561543, 'bagging_freq': 2, 'lambda_l1': 7.88235050608379, 'lambda_l2': 1.6042009983213312, 'min_gain_to_split': 0.4090987487321281, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:06,342] Trial 77 finished with value: 0.88179503872143 and parameters: {'learning_rate': 0.013798299338522994, 'num_leaves': 426, 'min_data_in_leaf': 140, 'feature_fraction': 0.8137178373640747, 'bagging_fraction': 0.5944537343188147, 'bagging_freq': 2, 'lambda_l1': 7.845973744324592, 'lambda_l2': 1.3808424055619923, 'min_gain_to_split': 0.4141945676883347, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:09,284] Trial 78 finished with value: 0.8800328080125034 and parameters: {'learning_rate': 0.013002810398526635, 'num_leaves': 454, 'min_data_in_leaf': 162, 'feature_fraction': 0.813193984342256, 'bagging_fraction': 0.6283769045477408, 'bagging_freq': 1, 'lambda_l1': 8.015217142570195, 'lambda_l2': 1.5834206186011017, 'min_gain_to_split': 0.39296432921210134, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:12,262] Trial 79 finished with value: 0.8804688161714859 and parameters: {'learning_rate': 0.018729746812880445, 'num_leaves': 507, 'min_data_in_leaf': 139, 'feature_fraction': 0.8548930453301814, 'bagging_fraction': 0.5853404294958403, 'bagging_freq': 2, 'lambda_l1': 8.310704123196157, 'lambda_l2': 0.6780763946929618, 'min_gain_to_split': 0.21735454823182243, 'max_depth': 14}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:15,252] Trial 80 finished with value: 0.8807267966999319 and parameters: {'learning_rate': 0.01363798396314892, 'num_leaves': 434, 'min_data_in_leaf': 142, 'feature_fraction': 0.8295947477038312, 'bagging_fraction': 0.5041234720923469, 'bagging_freq': 2, 'lambda_l1': 6.131939216148129, 'lambda_l2': 1.2823336368685925, 'min_gain_to_split': 0.3349850511915094, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:18,239] Trial 81 finished with value: 0.8812174741622716 and parameters: {'learning_rate': 0.010739261673542007, 'num_leaves': 424, 'min_data_in_leaf': 151, 'feature_fraction': 0.8738162434188356, 'bagging_fraction': 0.5946744137778649, 'bagging_freq': 3, 'lambda_l1': 7.602466830813867, 'lambda_l2': 2.3919518220429685, 'min_gain_to_split': 0.42323761911467594, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:21,835] Trial 82 finished with value: 0.8812899999838015 and parameters: {'learning_rate': 0.01342363111915002, 'num_leaves': 450, 'min_data_in_leaf': 160, 'feature_fraction': 0.8115359518807056, 'bagging_fraction': 0.6050566611262169, 'bagging_freq': 2, 'lambda_l1': 5.217428528628968, 'lambda_l2': 0.7297550996469812, 'min_gain_to_split': 0.5304619935217032, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:25,111] Trial 83 finished with value: 0.8803292924202317 and parameters: {'learning_rate': 0.01595667385839824, 'num_leaves': 391, 'min_data_in_leaf': 131, 'feature_fraction': 0.8655696673326034, 'bagging_fraction': 0.5360539391869329, 'bagging_freq': 3, 'lambda_l1': 7.035569406444278, 'lambda_l2': 1.7780975679200592, 'min_gain_to_split': 0.4851101748592774, 'max_depth': 14}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:28,839] Trial 84 finished with value: 0.8810696716023511 and parameters: {'learning_rate': 0.01063397055752137, 'num_leaves': 462, 'min_data_in_leaf': 198, 'feature_fraction': 0.8873245185826518, 'bagging_fraction': 0.562713079393349, 'bagging_freq': 1, 'lambda_l1': 5.84267926534389, 'lambda_l2': 1.4680319771531491, 'min_gain_to_split': 0.416574131541697, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:32,736] Trial 85 finished with value: 0.8801280739256556 and parameters: {'learning_rate': 0.012271272281215393, 'num_leaves': 431, 'min_data_in_leaf': 219, 'feature_fraction': 0.784760634265872, 'bagging_fraction': 0.6618410908129702, 'bagging_freq': 2, 'lambda_l1': 6.396014359363362, 'lambda_l2': 2.125908625556626, 'min_gain_to_split': 0.301188284102803, 'max_depth': 14}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:37,119] Trial 86 finished with value: 0.8808702908335958 and parameters: {'learning_rate': 0.014665599371427614, 'num_leaves': 498, 'min_data_in_leaf': 122, 'feature_fraction': 0.8425963844701699, 'bagging_fraction': 0.6896622192054359, 'bagging_freq': 3, 'lambda_l1': 7.927619724562893, 'lambda_l2': 2.720970515798941, 'min_gain_to_split': 0.4248277154601133, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:40,798] Trial 87 finished with value: 0.8809937283913453 and parameters: {'learning_rate': 0.015778959064683677, 'num_leaves': 443, 'min_data_in_leaf': 164, 'feature_fraction': 0.8103366858578802, 'bagging_fraction': 0.6220969361149254, 'bagging_freq': 2, 'lambda_l1': 6.05087076385141, 'lambda_l2': 0.10149163457355437, 'min_gain_to_split': 0.37152516519713885, 'max_depth': 14}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:43,932] Trial 88 finished with value: 0.8780751730121585 and parameters: {'learning_rate': 0.017809421803349053, 'num_leaves': 413, 'min_data_in_leaf': 235, 'feature_fraction': 0.7695324047285358, 'bagging_fraction': 0.6390051319535333, 'bagging_freq': 3, 'lambda_l1': 7.490770793842027, 'lambda_l2': 1.1321262360117208, 'min_gain_to_split': 0.25162613002464673, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:48,498] Trial 89 finished with value: 0.8799192413137567 and parameters: {'learning_rate': 0.010014455889208223, 'num_leaves': 469, 'min_data_in_leaf': 144, 'feature_fraction': 0.9379468216831655, 'bagging_fraction': 0.7071912506968754, 'bagging_freq': 5, 'lambda_l1': 6.540295189840181, 'lambda_l2': 0.41460898728592366, 'min_gain_to_split': 0.5168099351502479, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:51,663] Trial 90 finished with value: 0.8768759648803044 and parameters: {'learning_rate': 0.20514037812217625, 'num_leaves': 395, 'min_data_in_leaf': 182, 'feature_fraction': 0.8516450100978261, 'bagging_fraction': 0.5891189059284786, 'bagging_freq': 1, 'lambda_l1': 5.344129740442901, 'lambda_l2': 0.9336834571357759, 'min_gain_to_split': 0.34337822266655543, 'max_depth': 14}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:55,392] Trial 91 finished with value: 0.8815353967834152 and parameters: {'learning_rate': 0.013908231677854361, 'num_leaves': 475, 'min_data_in_leaf': 175, 'feature_fraction': 0.9182296302380041, 'bagging_fraction': 0.6107457410157158, 'bagging_freq': 3, 'lambda_l1': 7.230524227938482, 'lambda_l2': 2.3764621811750093, 'min_gain_to_split': 0.5358917057993184, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:30:59,203] Trial 92 finished with value: 0.8811358751097778 and parameters: {'learning_rate': 0.01103260698646074, 'num_leaves': 434, 'min_data_in_leaf': 154, 'feature_fraction': 0.8947255921269178, 'bagging_fraction': 0.6136771243985214, 'bagging_freq': 3, 'lambda_l1': 7.046950596046979, 'lambda_l2': 1.9235323109348377, 'min_gain_to_split': 0.3958637837839944, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:31:02,829] Trial 93 finished with value: 0.8814627490706963 and parameters: {'learning_rate': 0.012434729177977657, 'num_leaves': 480, 'min_data_in_leaf': 169, 'feature_fraction': 0.9208603328397766, 'bagging_fraction': 0.5760771430436307, 'bagging_freq': 2, 'lambda_l1': 7.765068055605247, 'lambda_l2': 2.5133571295873325, 'min_gain_to_split': 0.14443604808605398, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:31:06,116] Trial 94 finished with value: 0.8821225637968739 and parameters: {'learning_rate': 0.019482208809846482, 'num_leaves': 505, 'min_data_in_leaf': 207, 'feature_fraction': 0.8810894277053709, 'bagging_fraction': 0.5539820460762424, 'bagging_freq': 2, 'lambda_l1': 8.07902775496573, 'lambda_l2': 1.6401946314595417, 'min_gain_to_split': 0.11788144179319546, 'max_depth': 14}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:31:09,108] Trial 95 finished with value: 0.880716375284304 and parameters: {'learning_rate': 0.022773926229552863, 'num_leaves': 508, 'min_data_in_leaf': 210, 'feature_fraction': 0.873910531359496, 'bagging_fraction': 0.545464473691625, 'bagging_freq': 2, 'lambda_l1': 8.499212024733614, 'lambda_l2': 1.3910477794682206, 'min_gain_to_split': 0.14441250110524476, 'max_depth': 14}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:31:12,125] Trial 96 finished with value: 0.8815429169869258 and parameters: {'learning_rate': 0.019001472628189672, 'num_leaves': 496, 'min_data_in_leaf': 188, 'feature_fraction': 0.8373727386432875, 'bagging_fraction': 0.5192055897655464, 'bagging_freq': 2, 'lambda_l1': 8.866811481268424, 'lambda_l2': 1.7245128301204038, 'min_gain_to_split': 0.1154386683950617, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:31:15,152] Trial 97 finished with value: 0.8801983146953974 and parameters: {'learning_rate': 0.01972938878842637, 'num_leaves': 498, 'min_data_in_leaf': 202, 'feature_fraction': 0.8313273526710413, 'bagging_fraction': 0.6794170356180641, 'bagging_freq': 1, 'lambda_l1': 8.856534257807176, 'lambda_l2': 1.707172188722195, 'min_gain_to_split': 0.014890276059020713, 'max_depth': 14}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:31:17,880] Trial 98 finished with value: 0.8800889693133673 and parameters: {'learning_rate': 0.017010701403036933, 'num_leaves': 461, 'min_data_in_leaf': 189, 'feature_fraction': 0.8012138792554221, 'bagging_fraction': 0.4766145443897586, 'bagging_freq': 2, 'lambda_l1': 8.20088454715101, 'lambda_l2': 2.0782819394681855, 'min_gain_to_split': 0.03907756758557304, 'max_depth': 14}. Best is trial 71 with value: 0.8821519231182885.\n",
      "[I 2025-07-01 22:31:20,827] Trial 99 finished with value: 0.8803338778098937 and parameters: {'learning_rate': 0.015577088839907004, 'num_leaves': 499, 'min_data_in_leaf': 157, 'feature_fraction': 0.8642050061503352, 'bagging_fraction': 0.5293057575103276, 'bagging_freq': 2, 'lambda_l1': 9.549771867867271, 'lambda_l2': 0.9070705160112278, 'min_gain_to_split': 0.08402888469693792, 'max_depth': 15}. Best is trial 71 with value: 0.8821519231182885.\n",
      "âœ… Optimization completed!\n",
      "ðŸ† Best score: 0.8822\n",
      "ðŸŽ¯ Best params: {'learning_rate': 0.011710556955769997, 'num_leaves': 487, 'min_data_in_leaf': 177, 'feature_fraction': 0.8641050508298302, 'bagging_fraction': 0.6379813564261645, 'bagging_freq': 3, 'lambda_l1': 6.470615057588148, 'lambda_l2': 2.1244355495954323, 'min_gain_to_split': 0.27681932093474737, 'max_depth': 15}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 6. ADVANCED MODEL TRAINING\n",
    "# ================================\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Enhanced Optuna objective function\"\"\"\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 512),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 300),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 10.0),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 10.0),\n",
    "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'verbosity': -1,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'is_unbalance': True  # Handle class imbalance\n",
    "    }\n",
    "    \n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=2000,\n",
    "            valid_sets=[val_data],\n",
    "            callbacks=[lgb.early_stopping(100, verbose=False)]\n",
    "        )\n",
    "        \n",
    "        # Use probability predictions for better threshold optimization\n",
    "        y_pred_proba = model.predict(X_val)\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "        best_score = 0\n",
    "        for thresh in thresholds:\n",
    "            y_pred = (y_pred_proba > thresh).astype(int)\n",
    "            score = balanced_accuracy_score(y_val, y_pred)\n",
    "            best_score = max(best_score, score)\n",
    "        \n",
    "        scores.append(best_score)\n",
    "    \n",
    "    return np.mean(scores)\n",
    "\n",
    "print(\"ðŸš€ Starting enhanced hyperparameter optimization...\")\n",
    "\n",
    "# Create study with better configuration\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    study_name='enhanced_lgb_optimization',\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=30)\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
    "\n",
    "print(f\"âœ… Optimization completed!\")\n",
    "print(f\"ðŸ† Best score: {study.best_value:.4f}\")\n",
    "print(f\"ðŸŽ¯ Best params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86ffd43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Training final ensemble with optimal threshold...\n",
      "Training fold 1/7...\n",
      "  Fold 1 - Best threshold: 0.250, Score: 0.8871\n",
      "Training fold 2/7...\n",
      "  Fold 2 - Best threshold: 0.210, Score: 0.8867\n",
      "Training fold 3/7...\n",
      "  Fold 3 - Best threshold: 0.200, Score: 0.8854\n",
      "Training fold 4/7...\n",
      "  Fold 4 - Best threshold: 0.210, Score: 0.8856\n",
      "Training fold 5/7...\n",
      "  Fold 5 - Best threshold: 0.170, Score: 0.8722\n",
      "Training fold 6/7...\n",
      "  Fold 6 - Best threshold: 0.210, Score: 0.8702\n",
      "Training fold 7/7...\n",
      "  Fold 7 - Best threshold: 0.220, Score: 0.8894\n",
      "\n",
      "âœ… Cross-validation completed!\n",
      "ðŸŽ¯ Optimal threshold: 0.2100\n",
      "ðŸ† Final OOF Balanced Accuracy: 0.8821\n",
      "ðŸ“Š OOF predictions distribution: [33286  6734]\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 7. FINAL MODEL TRAINING WITH OPTIMAL THRESHOLD\n",
    "# ================================\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'is_unbalance': True\n",
    "})\n",
    "\n",
    "print(\"ðŸ”„ Training final ensemble with optimal threshold...\")\n",
    "\n",
    "# Cross-validation with threshold optimization\n",
    "skf = StratifiedKFold(n_splits=7, shuffle=True, random_state=2025)  # Increased folds\n",
    "oof_predictions = np.zeros(len(X))\n",
    "test_predictions = []\n",
    "models = []\n",
    "optimal_thresholds = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Training fold {fold + 1}/{skf.n_splits}...\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        best_params,\n",
    "        train_data,\n",
    "        num_boost_round=5000,\n",
    "        valid_sets=[val_data],\n",
    "        callbacks=[lgb.early_stopping(200, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    models.append(model)\n",
    "    \n",
    "    # Get validation predictions\n",
    "    val_pred_proba = model.predict(X_val)\n",
    "    oof_predictions[val_idx] = val_pred_proba\n",
    "    \n",
    "    # Find optimal threshold for this fold\n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "    best_threshold = 0.5\n",
    "    best_score = 0\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        y_pred = (val_pred_proba > thresh).astype(int)\n",
    "        score = balanced_accuracy_score(y_val, y_pred)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = thresh\n",
    "    \n",
    "    optimal_thresholds.append(best_threshold)\n",
    "    print(f\"  Fold {fold + 1} - Best threshold: {best_threshold:.3f}, Score: {best_score:.4f}\")\n",
    "    \n",
    "    # Test predictions for this fold\n",
    "    test_pred = model.predict(test_X)\n",
    "    test_predictions.append(test_pred)\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "# Calculate final scores\n",
    "final_threshold = np.mean(optimal_thresholds)\n",
    "oof_binary = (oof_predictions > final_threshold).astype(int)\n",
    "final_oof_score = balanced_accuracy_score(y, oof_binary)\n",
    "\n",
    "print(f\"\\nâœ… Cross-validation completed!\")\n",
    "print(f\"ðŸŽ¯ Optimal threshold: {final_threshold:.4f}\")\n",
    "print(f\"ðŸ† Final OOF Balanced Accuracy: {final_oof_score:.4f}\")\n",
    "print(f\"ðŸ“Š OOF predictions distribution: {np.bincount(oof_binary)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d66e1",
   "metadata": {},
   "source": [
    "## 4 â€“ Dataset assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "552be204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Generating final test predictions...\n",
      "ðŸ“Š Test predictions distribution: {0: 5328, 1: 1053}\n",
      "âœ… Improved submission saved to 'improved_submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 8. FINAL PREDICTIONS AND SUBMISSION\n",
    "# ================================\n",
    "\n",
    "print(\"ðŸ”„ Generating final test predictions...\")\n",
    "\n",
    "# Ensemble test predictions\n",
    "final_test_predictions = np.mean(test_predictions, axis=0)\n",
    "final_test_binary = (final_test_predictions > final_threshold).astype(int)\n",
    "\n",
    "# Create submission\n",
    "submission = sample.copy()\n",
    "submission['next_buy'] = final_test_binary\n",
    "\n",
    "print(f\"ðŸ“Š Test predictions distribution: {submission['next_buy'].value_counts().to_dict()}\")\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('improved_submission.csv', index=False)\n",
    "print(\"âœ… Improved submission saved to 'improved_submission.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e485b22d",
   "metadata": {},
   "source": [
    "## 5 â€“ Modeling helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a7bad72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Feature importance analysis...\n",
      "ðŸ” Top 15 most important features:\n",
      " 1. recency_days: 673854.74\n",
      " 2. PricePerUnit_max: 63266.31\n",
      " 3. Amount_sum: 37768.80\n",
      " 4. span_days: 21083.97\n",
      " 5. PricePerUnit_mean: 18145.23\n",
      " 6. MemberSeniority_days: 12078.41\n",
      " 7. frequency: 10965.93\n",
      " 8. City_encoded: 8042.70\n",
      " 9. CityFrequency: 7939.57\n",
      "10. TransactionID_nunique: 7869.04\n",
      "11. PricePerUnit_min: 4764.17\n",
      "12. Amount_max: 3088.03\n",
      "13. Amount_min: 2934.44\n",
      "14. PricePerUnit_std: 2537.90\n",
      "15. Hour_mean: 2486.39\n",
      "\n",
      "ðŸŽ‰ Model training completed!\n",
      "ðŸ“ˆ Expected significant improvement in score!\n",
      "ðŸ’¡ Key improvements made:\n",
      "   - Enhanced feature engineering with behavioral patterns\n",
      "   - Advanced hyperparameter optimization\n",
      "   - Optimal threshold search\n",
      "   - Increased cross-validation folds\n",
      "   - Better handling of class imbalance\n",
      "   - More sophisticated member demographics\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 9. FEATURE IMPORTANCE ANALYSIS\n",
    "# ================================\n",
    "\n",
    "print(\"\\nðŸ“Š Feature importance analysis...\")\n",
    "\n",
    "# Calculate feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': np.mean([model.feature_importance(importance_type='gain') for model in models], axis=0)\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"ðŸ” Top 15 most important features:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(15).iterrows()):\n",
    "    print(f\"{i+1:2d}. {row['feature']}: {row['importance']:.2f}\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Model training completed!\")\n",
    "print(f\"ðŸ“ˆ Expected significant improvement in score!\")\n",
    "print(f\"ðŸ’¡ Key improvements made:\")\n",
    "print(\"   - Enhanced feature engineering with behavioral patterns\")\n",
    "print(\"   - Advanced hyperparameter optimization\")\n",
    "print(\"   - Optimal threshold search\")\n",
    "print(\"   - Increased cross-validation folds\")\n",
    "print(\"   - Better handling of class imbalance\")\n",
    "print(\"   - More sophisticated member demographics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
